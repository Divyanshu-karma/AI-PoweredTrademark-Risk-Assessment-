# ðŸš€ Project Overview

## Purpose
This project builds an AI-powered trademark risk assessment system that analyzes trademark applications against the USPTO Trademark Manual of Examining Procedure (TMEP), November 2025 edition. The goal is to enable deterministic, retrieval-based legal analysis grounded strictly in official TMEP provisions.
This system automates the initial review by retrieving relevant TMEP provisions and generating a structured, citation-backed issue analysis.

## Problem statement
Trademark examination risk assessment is time-consuming and requires attorneys to manually compare application details against voluminous TMEP guidelines. The TMEP contains thousands of subsections, making fast and consistent issue identification difficult.

## Core Functionality
- The system takes a trademark application, searches a structured version of the TMEP manual, identifies possible examination issues supported by exact TMEP sections, and assigns risk levels using predefined rules â€” producing a structured, defensible risk report.

## Tech-Stack Used
### Frontend
- **Streamlit** â€“ Web-based UI for uploading trademark documents and displaying structured risk assessment reports.
- **HTML Rendering (via Streamlit components)** â€“ For structured, readable output formatting.

---

### âš™ Backend
- **Python** â€“ Core programming language for entire system.
- **FastAPI** â€“ Backend API framework for serving the RAG pipeline.
- **pdfplumber** â€“ PDF text extraction for trademark document ingestion.
- **Regex (re)** â€“ Structured parsing of LLM output.
- **dotenv** â€“ Environment variable management.

---

### ðŸ—„ Database / Vector Storage
- **Weaviate Cloud (Sandbox)** â€“ Managed vector database for semantic retrieval.
- **weaviate-client (Python v4)** â€“ Client SDK for schema creation, ingestion, and similarity search.
- **Bring-Your-Own-Embedding (BYOE) Architecture** â€“ External embedding generation, vectorizer disabled in DB.

---

### ðŸ¤– AI / ML Components
#### Retrieval Architecture
- **RAG (Retrieval-Augmented Generation)** â€“ Grounded legal reasoning framework.
- **Bi-Encoder Vector Retrieval** â€“ Separate passage and query embeddings.
- **Cosine Similarity Search (near_vector)** â€“ Semantic matching mechanism.

#### Embedding Models
- **SentenceTransformer** â€“ Embedding model interface.
- **intfloat/e5-base-v2** â€“ Embedding model used for:
  - "passage:" prefix (TMEP sections)
  - "query:" prefix (Trademark queries)
- L2 Normalized Embeddings â€“ For stable cosine similarity.

---

### ðŸ§  LLM Models
- **Groq Platform** â€“ Inference provider.
- **Llama 3.3 70B (Versatile)** â€“ Primary reasoning model for grounded legal issue analysis.
- **Llama 3.1 8B Instant** â€“ Lightweight alternative for faster inference/testing.

---

### ðŸ“¦ Core Python Libraries Used 
to be listed:
â€¢ `torch` â€“ Backend for embedding model execution.
â€¢ `transformers` â€“ Model loading and tokenizer support.
â€¢ `sentence-transformers` â€“ Embedding interface wrapper.
â€¢ `tqdm` â€“ Progress tracking during embedding generation.
â€¢ `json` â€“ Data serialization.
â€¢ `pathlib` â€“ File handling.
â€¢ `typing` â€“ Type annotations.</json>}```]]>}}}]}]}]}] }}}}]}}]}] }}}}]}}]}] }}}}]}}]}] }}}}]}}]}] }}}}]}}]}] }}}}]}}]}] }}}}]}}]}] }}}}]}}] }}



# Setup Instructions

## (1) for `parse_tmep_html.py`
- **Install Required Dependency:**
  ```bash
  pip install beautifulsoup4
  ```

## (2) for `normalize_sections.py`
- âœ” No additional pip installs required.
- You must already have: Parsed TMEP sections from `parse_tmep_html.py`

## (3) for chunk_sections.py
- âœ” No additional pip installs required.
- You must already have: `data/parsed/tmep_sections.json`
- Generated via: `parse_tmep_html.py` â†’ `normalize_sections.py`

# (4) for embed_chunks.py (E5 Query Embedding Layer)

## Install Required Dependencies
- `pip install sentence-transformers torch`

## Ensure Embedding Model Loader Exists
- `src/embeddings/model.py`

## Critical E5 Usage Rule
- `"query: " + query`
